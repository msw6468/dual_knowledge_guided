\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{naturemag-doi}
\citation{Rajkomar:2018:SAAD,Lakhani:2017:DLCR,Sutton:2020:AOCS}
\citation{Ng:2019:Incidence,Xie:2018:GlobalBurden}
\citation{Islam:2023:CKDP,Ghosh:2024:IOEM,Moon:2025:DPTK}
\babel@aux{english}{}
\citation{Kanakasabapathy:2021:AANN}
\citation{Guo:2022:EODG}
\citation{Harada:2022:Epidemiology}
\citation{Xu:2023:SimDE,Cugu:2022:ACVC}
\citation{Xu:2021:AFFDG,Zhao:2024:Morestyle,Liu:2024:UFDP,Huang:2021:FSDR}
\citation{Zhou:2021:DGWM}
\citation{Zhang:2018:Mixup}
\citation{Verma:2019:ManifoldMixup}
\citation{Yun:2019:Cutmix}
\citation{Uddin:2021:Saliencymix}
\citation{Qin:2020:Resizemix}
\citation{Zhang:2018:Mixup,Verma:2019:ManifoldMixup}
\citation{Yun:2019:Cutmix,Qin:2020:Resizemix,Uddin:2021:Saliencymix}
\citation{Balasubramanian:2023:TIIM}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \textbf  {Overview of our framework.} We presented a benchmark for evaluating model generalization performance under domain shift conditions (\textit  {i.e.}, single-source domain generalization). In this setting, we evaluated and analyzed the performance of models trained using clinical knowledge-guided data augmentation. }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:2.overview}{{1}{3}{\textbf {Overview of our framework.} We presented a benchmark for evaluating model generalization performance under domain shift conditions (\textit {i.e.}, single-source domain generalization). In this setting, we evaluated and analyzed the performance of models trained using clinical knowledge-guided data augmentation}{figure.caption.1}{}}
\newlabel{sec:similarity-guided-mixup}{{}{3}{}{figure.caption.1}{}}
\newlabel{sec:group-based-masking}{{}{4}{}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {Overview of KNOW-pedCKD dataset collection} }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:2.data_collection}{{2}{5}{\textbf {Overview of KNOW-pedCKD dataset collection}}{figure.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {Demographics and clinical characteristics}}}{5}{table.caption.3}\protected@file@percent }
\newlabel{tab:demographics}{{1}{5}{\textbf {Demographics and clinical characteristics}}{table.caption.3}{}}
\citation{Arjovsky2019InvariantRM}
\citation{Zhang:2018:Mixup}
\citation{Verma:2019:ManifoldMixup}
\citation{Kingma:2014:Adam}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {Statistical significance test results for features between the source and target domains.} P-values are reported for continuous variables, and chi-square test P-values are reported for categorical variables. A significant difference in distribution was observed for most features.}}{6}{table.caption.4}\protected@file@percent }
\newlabel{tab:ttest_results}{{2}{6}{\textbf {Statistical significance test results for features between the source and target domains.} P-values are reported for continuous variables, and chi-square test P-values are reported for categorical variables. A significant difference in distribution was observed for most features}{table.caption.4}{}}
\citation{Wong:2012:CKiDReview}
\citation{Ng:2023:PredictionTool}
\citation{Maaten:2008:tSNE}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  {Recall Performance Comparison in the Single-Source Domain Generalization Setting.} We present the center-wise performance across target domains (B, C and D) and the overall mean ($\pm $ standard deviation) across all centers, demonstrating that our proposed method achieves the highest Recall performance compared to all baselines.}}{7}{table.caption.5}\protected@file@percent }
\newlabel{tab:performance_mlp}{{3}{7}{\textbf {Recall Performance Comparison in the Single-Source Domain Generalization Setting.} We present the center-wise performance across target domains (B, C and D) and the overall mean ($\pm $ standard deviation) across all centers, demonstrating that our proposed method achieves the highest Recall performance compared to all baselines}{table.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \textbf  {Feature Space Analysis via t-SNE Visualization.} The plot visualizes the effect of each method by showing True Positives (TP) and False Negatives (FN) against the backdrop of the negative class (faded for clarity). Our method yields a highly structured feature space with robust separation between positive and negative classes, resulting in a decision boundary that is appropriately positioned to effectively maximize True Positive identification. }}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:2_feature_analysis}{{3}{8}{\textbf {Feature Space Analysis via t-SNE Visualization.} The plot visualizes the effect of each method by showing True Positives (TP) and False Negatives (FN) against the backdrop of the negative class (faded for clarity). Our method yields a highly structured feature space with robust separation between positive and negative classes, resulting in a decision boundary that is appropriately positioned to effectively maximize True Positive identification}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Center-wise Recall Analysis Demonstrating Robustness to Domain Shift.} The bar plot presents the recall score for each method across the individual target domains (B, C, and D), alongside the overall mean recall score. This center-wise breakdown highlights the robustness and generalization capability of our proposed method, which achieves the highest mean recall (78.79\%) and consistently high performance across all unseen target institutions}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:2_center_wise_analysis}{{4}{9}{\textbf {Center-wise Recall Analysis Demonstrating Robustness to Domain Shift.} The bar plot presents the recall score for each method across the individual target domains (B, C, and D), alongside the overall mean recall score. This center-wise breakdown highlights the robustness and generalization capability of our proposed method, which achieves the highest mean recall (78.79\%) and consistently high performance across all unseen target institutions}{figure.caption.7}{}}
\bibdata{sample}
\bibcite{Rajkomar:2018:SAAD}{1}
\bibcite{Lakhani:2017:DLCR}{2}
\bibcite{Sutton:2020:AOCS}{3}
\bibcite{Ng:2019:Incidence}{4}
\bibcite{Xie:2018:GlobalBurden}{5}
\bibcite{Islam:2023:CKDP}{6}
\bibcite{Ghosh:2024:IOEM}{7}
\bibcite{Moon:2025:DPTK}{8}
\bibcite{Kanakasabapathy:2021:AANN}{9}
\bibcite{Guo:2022:EODG}{10}
\bibcite{Harada:2022:Epidemiology}{11}
\bibcite{Xu:2023:SimDE}{12}
\bibcite{Cugu:2022:ACVC}{13}
\bibcite{Xu:2021:AFFDG}{14}
\bibcite{Zhao:2024:Morestyle}{15}
\bibcite{Liu:2024:UFDP}{16}
\bibcite{Huang:2021:FSDR}{17}
\bibcite{Zhou:2021:DGWM}{18}
\bibcite{Zhang:2018:Mixup}{19}
\bibcite{Verma:2019:ManifoldMixup}{20}
\bibcite{Yun:2019:Cutmix}{21}
\bibcite{Uddin:2021:Saliencymix}{22}
\bibcite{Qin:2020:Resizemix}{23}
\@writefile{toc}{\contentsline {section}{\hspace  *{-\tocsep }References}{10}{figure.caption.7}\protected@file@percent }
\bibcite{Balasubramanian:2023:TIIM}{24}
\bibcite{Arjovsky2019InvariantRM}{25}
\bibcite{Kingma:2014:Adam}{26}
\bibcite{Wong:2012:CKiDReview}{27}
\bibcite{Ng:2023:PredictionTool}{28}
\bibcite{Maaten:2008:tSNE}{29}
\ttl@finishall
\newlabel{LastPage}{{}{11}{}{page.11}{}}
\gdef\lastpage@lastpage{11}
\gdef\lastpage@lastpageHy{11}
\gdef \@abspage@last{11}
